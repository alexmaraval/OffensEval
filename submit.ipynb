{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/barthelemyduthoit/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "      <th>clean_tweets</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86426</td>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ask nativ american</td>\n",
       "      <td>[ask, nativ, american]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90194</td>\n",
       "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "      <td>home drunk manga trump</td>\n",
       "      <td>[home, drunk, manga, trump]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16820</td>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amazon investig chines employe sell intern dat...</td>\n",
       "      <td>[amazon, investig, chines, employe, sell, inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62688</td>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>someon retaken piec shit volcano</td>\n",
       "      <td>[someon, retaken, piec, shit, volcano]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43605</td>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>obama want liber amp illeg move red state</td>\n",
       "      <td>[obama, want, liber, amp, illeg, move, red, st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet subtask_a  \\\n",
       "0  86426  @USER She should ask a few native Americans wh...       OFF   \n",
       "1  90194  @USER @USER Go home you’re drunk!!! @USER #MAG...       OFF   \n",
       "2  16820  Amazon is investigating Chinese employees who ...       NOT   \n",
       "3  62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n",
       "4  43605  @USER @USER Obama wanted liberals &amp; illega...       NOT   \n",
       "\n",
       "  subtask_b subtask_c                                       clean_tweets  \\\n",
       "0       UNT       NaN                                 ask nativ american   \n",
       "1       TIN       IND                             home drunk manga trump   \n",
       "2       NaN       NaN  amazon investig chines employe sell intern dat...   \n",
       "3       UNT       NaN                   someon retaken piec shit volcano   \n",
       "4       NaN       NaN          obama want liber amp illeg move red state   \n",
       "\n",
       "                                              tokens  \n",
       "0                             [ask, nativ, american]  \n",
       "1                        [home, drunk, manga, trump]  \n",
       "2  [amazon, investig, chines, employe, sell, inte...  \n",
       "3             [someon, retaken, piec, shit, volcano]  \n",
       "4  [obama, want, liber, amp, illeg, move, red, st...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import utils.preprocessing\n",
    "from utils.utils import make_submission\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/raw/offenseval-training-v1.tsv', sep='\\t')\n",
    "utils.preprocessing.clean(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X = df[\"clean_tweets\"]\n",
    "\n",
    "vec = CountVectorizer(ngram_range=(1,3), \n",
    "                      stop_words='english', \n",
    "                      max_features=32500)\n",
    "\n",
    "df_test = pd.read_csv('data/test/task_a/testset-taska.tsv', sep='\\t')\n",
    "utils.preprocessing.clean(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtask A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vec.fit_transform(X)\n",
    "X_test = vec.transform(df_test[\"clean_tweets\"])\n",
    "y_train = df[\"subtask_a\"].map({\"OFF\":0, \"NOT\":1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=4, dual=True)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "#make_submission(y_pred, {0:\"OFF\", 1:\"NOT\"}, df_test, \"submissions/taska_logreg.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import sequence\n",
    "from utils.keras_utils import f1_loss\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Embedding, Bidirectional, LSTM, GlobalMaxPool1D, Dropout, Dense\n",
    "from keras.preprocessing import text\n",
    "\n",
    "tokenizer = text.Tokenizer(num_words=15000)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(15000, 16, input_length=100))\n",
    "model.add(Bidirectional(LSTM(6, return_sequences=True)))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(6, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "y_cat = to_categorical(y_train)\n",
    "tokenizer.fit_on_texts(X)\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(X)\n",
    "X_test = df_test[\"clean_tweets\"]\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_tr = sequence.pad_sequences(list_tokenized_train, maxlen=100)\n",
    "X_te = sequence.pad_sequences(list_tokenized_test, maxlen=100)\n",
    "model.compile(loss=f1_loss, optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_tr, y_cat, epochs=4,  batch_size=64)\n",
    "y_pred_proba = model.predict(X_te)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "#make_submission(y_pred, {0:\"OFF\", 1:\"NOT\"}, df_test, \"submissions/taska_lstm.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble RF + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=4, dual=True)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_proba_logreg = logreg.predict_proba(X_test)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_proba_rf = rf.predict_proba(X_test)\n",
    "\n",
    "y_pred_proba = y_pred_proba_logreg + y_pred_proba_rf\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "make_submission(y_pred, {0:\"OFF\", 1:\"NOT\"}, df_test, \"submissions/taska_logreg+rf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

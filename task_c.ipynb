{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "submit.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "9hve3myFrnFG",
        "colab_type": "code",
        "outputId": "20df269d-3d16-401f-cce1-491624e43c6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "import utils.preprocessing\n",
        "from utils.test_model import *\n",
        "from utils.utils import make_submission\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('data/raw/offenseval-training-v1.tsv', sep='\\t')\n",
        "utils.preprocessing.clean(df)\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting symspellpy\n",
            "  Downloading https://files.pythonhosted.org/packages/60/0d/f46a1a98fbaee317ff006134b2ced63e71ca57e63e71c9aa62d74b655a22/symspellpy-6.3.7-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.13.1 in /usr/local/lib/python3.6/dist-packages (from symspellpy) (1.14.6)\n",
            "Installing collected packages: symspellpy\n",
            "Successfully installed symspellpy-6.3.7\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_c</th>\n",
              "      <th>clean_tweets</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>86426</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ask nativ american</td>\n",
              "      <td>[ask, nativ, american]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>90194</td>\n",
              "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "      <td>home drunk manga trump</td>\n",
              "      <td>[home, drunk, manga, trump]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16820</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>amazon investig chines employe sell intern dat...</td>\n",
              "      <td>[amazon, investig, chines, employe, sell, inte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>62688</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>someon retaken piec shit volcano</td>\n",
              "      <td>[someon, retaken, piec, shit, volcano]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>43605</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>obama want liber amp illeg move red state</td>\n",
              "      <td>[obama, want, liber, amp, illeg, move, red, st...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                              tweet subtask_a  \\\n",
              "0  86426  @USER She should ask a few native Americans wh...       OFF   \n",
              "1  90194  @USER @USER Go home you’re drunk!!! @USER #MAG...       OFF   \n",
              "2  16820  Amazon is investigating Chinese employees who ...       NOT   \n",
              "3  62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n",
              "4  43605  @USER @USER Obama wanted liberals &amp; illega...       NOT   \n",
              "\n",
              "  subtask_b subtask_c                                       clean_tweets  \\\n",
              "0       UNT       NaN                                 ask nativ american   \n",
              "1       TIN       IND                             home drunk manga trump   \n",
              "2       NaN       NaN  amazon investig chines employe sell intern dat...   \n",
              "3       UNT       NaN                   someon retaken piec shit volcano   \n",
              "4       NaN       NaN          obama want liber amp illeg move red state   \n",
              "\n",
              "                                              tokens  \n",
              "0                             [ask, nativ, american]  \n",
              "1                        [home, drunk, manga, trump]  \n",
              "2  [amazon, investig, chines, employe, sell, inte...  \n",
              "3             [someon, retaken, piec, shit, volcano]  \n",
              "4  [obama, want, liber, amp, illeg, move, red, st...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "bzcNUPrqrnFV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "\n",
        "#df = df.dropna(axis=0, subset=['clean_tweets','subtask_c'])\n",
        "X = df[\"clean_tweets\"]\n",
        "\n",
        "vec = CountVectorizer(ngram_range=(1,3), \n",
        "                      stop_words='english', \n",
        "                      max_features=10000)\n",
        "\n",
        "df_test = pd.read_csv('data/test/task_c/test_set_taskc.tsv', sep='\\t')\n",
        "utils.preprocessing.clean(df_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b9-IaZvIHyNa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "54bf7047-360b-4b05-f1a5-f580636b069b"
      },
      "cell_type": "code",
      "source": [
        "y_train = df[\"subtask_c\"].map({\"IND\":0, \"GRP\":1, \"OTH\":2})\n",
        "\n",
        "\n",
        "# remove rows with NaN as label in y_train and X then build X_train\n",
        "(nan_idx,) = np.where(~np.isnan(y_train))\n",
        "print('Nan proportion (removed): {}%'.format(100*round(1-len(nan_idx) / y_train.shape[0], 4)))\n",
        "\n",
        "# clean from NaNs ans reset index to prevent errors in testing\n",
        "y_train = y_train.dropna().reset_index()['subtask_c']\n",
        "X_new = X.iloc[nan_idx].reset_index()['clean_tweets']"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nan proportion (removed): 70.73%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cicoRmI1rnFd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Subtask C"
      ]
    },
    {
      "metadata": {
        "id": "_Ocwpi7KrnFg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = vec.fit_transform(X_new)\n",
        "X_test = vec.transform(df_test[\"clean_tweets\"])\n",
        "#y_train = df[\"subtask_c\"].map({\"IND\":0, \"GRP\":1, \"OTH\":2})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "55PaLOOmrnFn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "metadata": {
        "id": "12uc8bP2rnFp",
        "colab_type": "code",
        "outputId": "018f81c5-7feb-43be-b814-968bc93d2e84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2009
        }
      },
      "cell_type": "code",
      "source": [
        "acc_scores_logreg = np.zeros(10)\n",
        "f1_scores_logreg = np.zeros(10)\n",
        "\n",
        "for i in range(10):\n",
        "  logreg = LogisticRegression(C=i+1, dual=True)\n",
        "  print(logreg)\n",
        "  print('=================================================================')\n",
        "\n",
        "  # Train Model\n",
        "  print('=========================== Training ============================')\n",
        "  logreg.fit(X_train, y_train)\n",
        "\n",
        "  # Evaluate Model\n",
        "  print('========================== Evaluating ===========================')\n",
        "  print('Accuracy:\\t{}'.format(round(100*logreg.score(X_train, y_train),4)))\n",
        "\n",
        "  # K-Fold Cross Validation\n",
        "  print('========================== Validating ===========================')\n",
        "  (f1_logreg, acc_logreg) = test_single_model(logreg, X_new, y_train, vec, n_splits=2, random_state=1)\n",
        "  acc_scores_logreg[i] = acc_logreg\n",
        "  f1_scores_logreg[i] = f1_logreg\n",
        "  print('Mean F1 score (3-fold CV):\\t{}%'.format(round(100*f1_logreg,4)))\n",
        "  print('Mean Accuracy (3-fold CV):\\t{}%'.format(round(100*acc_logreg,4)))\n",
        "\n",
        "# Predict on test set and write submission\n",
        "#y_pred_proba_logreg = logreg.predict_proba(X_test)\n",
        "#y_pred_logreg = np.argmax(y_pred_proba_logreg,1)\n",
        "#make_submission(y_pred_logreg, {\"UNT\":0, \"TIN\":1}, df_test, \"submissions/taskb_logreg.csv\")"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
            "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
            "          tol=0.0001, verbose=0, warm_start=False)\n",
            "=================================================================\n",
            "=========================== Training ============================\n",
            "========================== Evaluating ===========================\n",
            "Accuracy:\t93.4985\n",
            "========================== Validating ===========================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mean F1 score (3-fold CV):\t45.327%\n",
            "Mean Accuracy (3-fold CV):\t67.5181%\n",
            "LogisticRegression(C=2, class_weight=None, dual=True, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
            "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
            "          tol=0.0001, verbose=0, warm_start=False)\n",
            "=================================================================\n",
            "=========================== Training ============================\n",
            "========================== Evaluating ===========================\n",
            "Accuracy:\t95.9494\n",
            "========================== Validating ===========================\n",
            "Mean F1 score (3-fold CV):\t45.55%\n",
            "Mean Accuracy (3-fold CV):\t66.8215%\n",
            "LogisticRegression(C=3, class_weight=None, dual=True, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
            "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
            "          tol=0.0001, verbose=0, warm_start=False)\n",
            "=================================================================\n",
            "=========================== Training ============================\n",
            "========================== Evaluating ===========================\n",
            "Accuracy:\t97.1362\n",
            "========================== Validating ===========================\n",
            "Mean F1 score (3-fold CV):\t46.1738%\n",
            "Mean Accuracy (3-fold CV):\t66.6409%\n",
            "LogisticRegression(C=4, class_weight=None, dual=True, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
            "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
            "          tol=0.0001, verbose=0, warm_start=False)\n",
            "=================================================================\n",
            "=========================== Training ============================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "========================== Evaluating ===========================\n",
            "Accuracy:\t97.4974\n",
            "========================== Validating ===========================\n",
            "Mean F1 score (3-fold CV):\t46.058%\n",
            "Mean Accuracy (3-fold CV):\t66.3829%\n",
            "LogisticRegression(C=5, class_weight=None, dual=True, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
            "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
            "          tol=0.0001, verbose=0, warm_start=False)\n",
            "=================================================================\n",
            "=========================== Training ============================\n",
            "========================== Evaluating ===========================\n",
            "Accuracy:\t97.8328\n",
            "========================== Validating ===========================\n",
            "Mean F1 score (3-fold CV):\t46.524%\n",
            "Mean Accuracy (3-fold CV):\t66.5893%\n",
            "LogisticRegression(C=6, class_weight=None, dual=True, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
            "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
            "          tol=0.0001, verbose=0, warm_start=False)\n",
            "=================================================================\n",
            "=========================== Training ============================\n",
            "========================== Evaluating ===========================\n",
            "Accuracy:\t98.1424\n",
            "========================== Validating ===========================\n",
            "Mean F1 score (3-fold CV):\t46.3543%\n",
            "Mean Accuracy (3-fold CV):\t66.3313%\n",
            "LogisticRegression(C=7, class_weight=None, dual=True, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
            "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
            "          tol=0.0001, verbose=0, warm_start=False)\n",
            "=================================================================\n",
            "=========================== Training ============================\n",
            "========================== Evaluating ===========================\n",
            "Accuracy:\t98.2456\n",
            "========================== Validating ===========================\n",
            "Mean F1 score (3-fold CV):\t46.2921%\n",
            "Mean Accuracy (3-fold CV):\t66.2281%\n",
            "LogisticRegression(C=8, class_weight=None, dual=True, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
            "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
            "          tol=0.0001, verbose=0, warm_start=False)\n",
            "=================================================================\n",
            "=========================== Training ============================\n",
            "========================== Evaluating ===========================\n",
            "Accuracy:\t98.5294\n",
            "========================== Validating ===========================\n",
            "Mean F1 score (3-fold CV):\t46.2278%\n",
            "Mean Accuracy (3-fold CV):\t66.1507%\n",
            "LogisticRegression(C=9, class_weight=None, dual=True, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
            "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
            "          tol=0.0001, verbose=0, warm_start=False)\n",
            "=================================================================\n",
            "=========================== Training ============================\n",
            "========================== Evaluating ===========================\n",
            "Accuracy:\t98.71\n",
            "========================== Validating ===========================\n",
            "Mean F1 score (3-fold CV):\t46.2681%\n",
            "Mean Accuracy (3-fold CV):\t65.9959%\n",
            "LogisticRegression(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
            "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
            "          tol=0.0001, verbose=0, warm_start=False)\n",
            "=================================================================\n",
            "=========================== Training ============================\n",
            "========================== Evaluating ===========================\n",
            "Accuracy:\t98.839\n",
            "========================== Validating ===========================\n",
            "Mean F1 score (3-fold CV):\t46.0481%\n",
            "Mean Accuracy (3-fold CV):\t65.8153%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C1I46tFupHo_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "c3e6b82f-4524-427e-b8d6-c41f728e0d82"
      },
      "cell_type": "code",
      "source": [
        "plt.scatter([i+1 for i in range(10)], acc_scores_logreg, label='accuracy')\n",
        "plt.scatter([i+1 for i in range(10)], f1_scores_logreg, label='f1_score')\n",
        "plt.legend()\n",
        "plt.xlabel('C')\n",
        "plt.savefig('logreg_scores_taskc.png')\n",
        "plt.show()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFYCAYAAABpkTT0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0VQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "lHSAOne4hh4t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Ridge Regression"
      ]
    },
    {
      "metadata": {
        "id": "zoIuP8E2hMYR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3417
        },
        "outputId": "0c6d4de9-78cf-46ec-9556-f1d541601e1f"
      },
      "cell_type": "code",
      "source": [
        "acc_scores = np.zeros(20)\n",
        "f1_scores = np.zeros(20)\n",
        "\n",
        "for i in range(20):\n",
        "  alpha = 0.05 * i\n",
        "  ridgereg = RidgeClassifier(alpha = alpha)\n",
        "  print(ridgereg)\n",
        "  print('=================================================================')\n",
        "\n",
        "  # Train Model\n",
        "  print('=========================== Training ============================')\n",
        "  ridgereg.fit(X_train, y_train)\n",
        "\n",
        "  # Evaluate Model\n",
        "  print('========================== Evaluating ===========================')\n",
        "  print('Accuracy:\\t{}'.format(round(100*ridgereg.score(X_train, y_train),4)))\n",
        "\n",
        "  # K-Fold Cross Validation\n",
        "  print('========================== Validating ===========================')\n",
        "  (f1_ridgereg, acc_ridgereg) = test_single_model(ridgereg, X_new, y_train, vec, n_splits=3, random_state=1)\n",
        "  acc_scores[i] = acc_ridgereg\n",
        "  f1_scores[i] = f1_ridgereg\n",
        "  print('Mean F1 score (3-fold CV):\\t{}%'.format(round(100*f1_ridgereg,4)))\n",
        "  print('Mean Accuracy (3-fold CV):\\t{}%'.format(round(100*acc_ridgereg,4)))\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RidgeClassifier(alpha=0.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
            "        max_iter=None, normalize=False, random_state=None, solver='auto',\n",
            "        tol=0.001)\n",
            "=================================================================\n",
            "=========================== Training ============================\n",
            "========================== Evaluating ===========================\n",
            "Accuracy:\t98.8906\n",
            "========================== Validating ===========================\n",
            "Mean F1 score (3-fold CV):\t44.8502%\n",
            "Mean Accuracy (3-fold CV):\t60.8359%\n",
            "RidgeClassifier(alpha=0.05, class_weight=None, copy_X=True,\n",
            "        fit_intercept=True, max_iter=None, normalize=False,\n",
            "        random_state=None, solver='auto', tol=0.001)\n",
            "=================================================================\n",
            "=========================== Training ============================\n",
            "========================== Evaluating ===========================\n",
            "Accuracy:\t98.839\n",
            "========================== Validating ===========================\n",
            "Mean F1 score (3-fold CV):\t44.8323%\n",
            "Mean Accuracy (3-fold CV):\t61.1971%\n",
            "RidgeClassifier(alpha=0.1, class_weight=None, copy_X=True, fit_intercept=True,\n",
            "        max_iter=None, normalize=False, random_state=None, solver='auto',\n",
            "        tol=0.001)\n",
            "=================================================================\n",
            "=========================== Training ============================\n",
            "========================== Evaluating ===========================\n",
            "Accuracy:\t98.7616\n",
            "========================== Validating ===========================\n",
            "Mean F1 score (3-fold CV):\t45.1022%\n",
            "Mean Accuracy (3-fold CV):\t61.5067%\n",
            "RidgeClassifier(alpha=0.15000000000000002, class_weight=None, copy_X=True,\n",
            "        fit_intercept=True, max_iter=None, normalize=False,\n",
            "        random_state=None, solver='auto', tol=0.001)\n",
            "=================================================================\n",
            "=========================== Training ============================\n",
            "========================== Evaluating ===========================\n",
            "Accuracy:\t98.6584\n",
            "========================== Validating ===========================\n",
            "Mean F1 score (3-fold CV):\t45.2046%\n",
            "Mean Accuracy (3-fold CV):\t61.7131%\n",
            "RidgeClassifier(alpha=0.2, class_weight=None, copy_X=True, fit_intercept=True,\n",
            "        max_iter=None, normalize=False, random_state=None, solver='auto',\n",
            "        tol=0.001)\n",
            "=================================================================\n",
            "=========================== Training ============================\n",
            "========================== Evaluating ===========================\n",
            "Accuracy:\t98.5294\n",
            "========================== Validating ===========================\n",
            "Mean F1 score (3-fold CV):\t45.1739%\n",
            "Mean Accuracy (3-fold CV):\t61.9453%\n",
            "RidgeClassifier(alpha=0.25, class_weight=None, copy_X=True,\n",
            "        fit_intercept=True, max_iter=None, normalize=False,\n",
            "        random_state=None, solver='auto', tol=0.001)\n",
            "=================================================================\n",
            "=========================== Training ============================\n",
            "========================== Evaluating ===========================\n",
            "Accuracy:\t98.4778\n",
            "========================== Validating ===========================\n",
            "Mean F1 score (3-fold CV):\t45.3724%\n",
            "Mean Accuracy (3-fold CV):\t62.2549%\n",
            "RidgeClassifier(alpha=0.30000000000000004, class_weight=None, copy_X=True,\n",
            "        fit_intercept=True, max_iter=None, normalize=False,\n",
            "        random_state=None, solver='auto', tol=0.001)\n",
            "=================================================================\n",
            "=========================== Training ============================\n",
            "========================== Evaluating ===========================\n",
            "Accuracy:\t98.3746\n",
            "========================== Validating ===========================\n",
            "Mean F1 score (3-fold CV):\t45.5548%\n",
            "Mean Accuracy (3-fold CV):\t62.5129%\n",
            "RidgeClassifier(alpha=0.35000000000000003, class_weight=None, copy_X=True,\n",
            "        fit_intercept=True, max_iter=None, normalize=False,\n",
            "        random_state=None, solver='auto', tol=0.001)\n",
            "=================================================================\n",
            "=========================== Training ============================\n",
            "========================== Evaluating ===========================\n",
            "Accuracy:\t98.2714\n",
            "========================== Validating ===========================\n",
            "Mean F1 score (3-fold CV):\t45.7406%\n",
            "Mean Accuracy (3-fold CV):\t62.7709%\n",
            "RidgeClassifier(alpha=0.4, class_weight=None, copy_X=True, fit_intercept=True,\n",
            "        max_iter=None, normalize=False, random_state=None, solver='auto',\n",
            "        tol=0.001)\n",
            "=================================================================\n",
            "=========================== Training ============================\n",
            "========================== Evaluating ===========================\n",
            "Accuracy:\t98.1682\n",
            "========================== Validating ===========================\n",
            "Mean F1 score (3-fold CV):\t45.8946%\n",
            "Mean Accuracy (3-fold CV):\t63.0031%\n",
            "RidgeClassifier(alpha=0.45, class_weight=None, copy_X=True,\n",
            "        fit_intercept=True, max_iter=None, normalize=False,\n",
            "        random_state=None, solver='auto', tol=0.001)\n",
            "=================================================================\n",
            "=========================== Training ============================\n",
            "========================== Evaluating ===========================\n",
            "Accuracy:\t98.1166\n",
            "========================== Validating ===========================\n",
            "Mean F1 score (3-fold CV):\t46.1105%\n",
            "Mean Accuracy (3-fold CV):\t63.1837%\n",
            "RidgeClassifier(alpha=0.5, class_weight=None, copy_X=True, fit_intercept=True,\n",
            "        max_iter=None, normalize=False, random_state=None, solver='auto',\n",
            "        tol=0.001)\n",
            "=================================================================\n",
            "=========================== Training ============================\n",
            "========================== Evaluating ===========================\n",
            "Accuracy:\t98.0134\n",
            "========================== Validating ===========================\n",
            "Mean F1 score (3-fold CV):\t46.2944%\n",
            "Mean Accuracy (3-fold CV):\t63.4675%\n",
            "RidgeClassifier(alpha=0.55, class_weight=None, copy_X=True,\n",
            "        fit_intercept=True, max_iter=None, normalize=False,\n",
            "        random_state=None, solver='auto', tol=0.001)\n",
            "=================================================================\n",
            "=========================== Training ============================\n",
            "========================== Evaluating ===========================\n",
            "Accuracy:\t97.9618\n",
            "========================== Validating ===========================\n",
            "Mean F1 score (3-fold CV):\t46.293%\n",
            "Mean Accuracy (3-fold CV):\t63.4675%\n",
            "RidgeClassifier(alpha=0.6000000000000001, class_weight=None, copy_X=True,\n",
            "        fit_intercept=True, max_iter=None, normalize=False,\n",
            "        random_state=None, solver='auto', tol=0.001)\n",
            "=================================================================\n",
            "=========================== Training ============================\n",
            "========================== Evaluating ===========================\n",
            "Accuracy:\t97.8328\n",
            "========================== Validating ===========================\n",
            "Mean F1 score (3-fold CV):\t46.2376%\n",
            "Mean Accuracy (3-fold CV):\t63.5449%\n",
            "RidgeClassifier(alpha=0.65, class_weight=None, copy_X=True,\n",
            "        fit_intercept=True, max_iter=None, normalize=False,\n",
            "        random_state=None, solver='auto', tol=0.001)\n",
            "=================================================================\n",
            "=========================== Training ============================\n",
            "========================== Evaluating ===========================\n",
            "Accuracy:\t97.807\n",
            "========================== Validating ===========================\n",
            "Mean F1 score (3-fold CV):\t45.9638%\n",
            "Mean Accuracy (3-fold CV):\t63.5707%\n",
            "RidgeClassifier(alpha=0.7000000000000001, class_weight=None, copy_X=True,\n",
            "        fit_intercept=True, max_iter=None, normalize=False,\n",
            "        random_state=None, solver='auto', tol=0.001)\n",
            "=================================================================\n",
            "=========================== Training ============================\n",
            "========================== Evaluating ===========================\n",
            "Accuracy:\t97.678\n",
            "========================== Validating ===========================\n",
            "Mean F1 score (3-fold CV):\t45.8944%\n",
            "Mean Accuracy (3-fold CV):\t63.6997%\n",
            "RidgeClassifier(alpha=0.75, class_weight=None, copy_X=True,\n",
            "        fit_intercept=True, max_iter=None, normalize=False,\n",
            "        random_state=None, solver='auto', tol=0.001)\n",
            "=================================================================\n",
            "=========================== Training ============================\n",
            "========================== Evaluating ===========================\n",
            "Accuracy:\t97.6522\n",
            "========================== Validating ===========================\n",
            "Mean F1 score (3-fold CV):\t45.9791%\n",
            "Mean Accuracy (3-fold CV):\t63.8029%\n",
            "RidgeClassifier(alpha=0.8, class_weight=None, copy_X=True, fit_intercept=True,\n",
            "        max_iter=None, normalize=False, random_state=None, solver='auto',\n",
            "        tol=0.001)\n",
            "=================================================================\n",
            "=========================== Training ============================\n",
            "========================== Evaluating ===========================\n",
            "Accuracy:\t97.5232\n",
            "========================== Validating ===========================\n",
            "Mean F1 score (3-fold CV):\t45.6309%\n",
            "Mean Accuracy (3-fold CV):\t63.6481%\n",
            "RidgeClassifier(alpha=0.8500000000000001, class_weight=None, copy_X=True,\n",
            "        fit_intercept=True, max_iter=None, normalize=False,\n",
            "        random_state=None, solver='auto', tol=0.001)\n",
            "=================================================================\n",
            "=========================== Training ============================\n",
            "========================== Evaluating ===========================\n",
            "Accuracy:\t97.5232\n",
            "========================== Validating ===========================\n",
            "Mean F1 score (3-fold CV):\t45.6624%\n",
            "Mean Accuracy (3-fold CV):\t63.7771%\n",
            "RidgeClassifier(alpha=0.9, class_weight=None, copy_X=True, fit_intercept=True,\n",
            "        max_iter=None, normalize=False, random_state=None, solver='auto',\n",
            "        tol=0.001)\n",
            "=================================================================\n",
            "=========================== Training ============================\n",
            "========================== Evaluating ===========================\n",
            "Accuracy:\t97.4716\n",
            "========================== Validating ===========================\n",
            "Mean F1 score (3-fold CV):\t45.401%\n",
            "Mean Accuracy (3-fold CV):\t63.6997%\n",
            "RidgeClassifier(alpha=0.9500000000000001, class_weight=None, copy_X=True,\n",
            "        fit_intercept=True, max_iter=None, normalize=False,\n",
            "        random_state=None, solver='auto', tol=0.001)\n",
            "=================================================================\n",
            "=========================== Training ============================\n",
            "========================== Evaluating ===========================\n",
            "Accuracy:\t97.42\n",
            "========================== Validating ===========================\n",
            "Mean F1 score (3-fold CV):\t45.4152%\n",
            "Mean Accuracy (3-fold CV):\t63.8803%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pGaelOLCl_c8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "32dec0b2-f85e-4b5a-cf95-9a85d2d65e9b"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter([i*0.05 for i in range(20)], acc_scores, label='accuracy')\n",
        "plt.scatter([i*0.05 for i in range(20)], f1_scores, label='f1_score')\n",
        "plt.legend()\n",
        "plt.xlabel('alpha')\n",
        "plt.savefig('ridgereg_scores_taskc.png')\n",
        "plt.show()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfEAAAFYCAYAAABDIcVbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERERk/r/AYqdEIEM1GvIAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "HL2v5DZ5a3cr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Linear SVC"
      ]
    },
    {
      "metadata": {
        "id": "diR-krUPW-cM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "92884b94-5147-419d-cd8a-cdb783d851a4"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svc = SVC(C=4, kernel='sigmoid', shrinking=True, decision_function_shape='ovo', probability=True)\n",
        "print(svc)\n",
        "print('=================================================================')\n",
        "\n",
        "# Train Model\n",
        "print('=========================== Training ============================')\n",
        "svc.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate Model\n",
        "print('========================== Evaluating ===========================')\n",
        "print('Accuracy:\\t{}'.format(round(100*svc.score(X_train, y_train),4)))\n",
        "\n",
        "# K-Fold Cross Validation\n",
        "print('========================== Validating ===========================')\n",
        "(f1_svc, acc_svc) = test_single_model(svc, X_new, y_train, vec, n_splits=3, random_state=1)\n",
        "print('Mean F1 score (3-fold CV):\\t{}%'.format(round(100*f1_svc,4)))\n",
        "print('Mean Accuracy (3-fold CV):\\t{}%'.format(round(100*acc_svc,4)))\n",
        "\n",
        "# Predict on test set and write submission\n",
        "#y_pred_proba_svc = svc.predict_proba(X_test)\n",
        "#y_pred_svc = np.argmax(y_pred_proba_svc,1)\n",
        "#make_submission(y_pred_svc, {\"UNT\":0, \"TIN\":1}, df_test, \"submissions/taskb_svc.csv\")"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVC(C=4, cache_size=200, class_weight=None, coef0=0.0,\n",
            "  decision_function_shape='ovo', degree=3, gamma='auto_deprecated',\n",
            "  kernel='sigmoid', max_iter=-1, probability=True, random_state=None,\n",
            "  shrinking=True, tol=0.001, verbose=False)\n",
            "=================================================================\n",
            "=========================== Training ============================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "========================== Evaluating ===========================\n",
            "Accuracy:\t62.1001\n",
            "========================== Validating ===========================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mean F1 score (3-fold CV):\t25.5383%\n",
            "Mean Accuracy (3-fold CV):\t62.1001%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DmduYh55a-aa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ]
    },
    {
      "metadata": {
        "id": "KTDoJW9wXKWm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from scipy.sparse import hstack\n",
        "\n",
        "word_vec = CountVectorizer(ngram_range=(1,3), stop_words='english',analyzer='word', max_features=32500)\n",
        "train_word_features = word_vec.fit_transform(X_new)\n",
        "test_word_features = word_vec.fit_transform(df_test[\"clean_tweets\"])\n",
        "\n",
        "char_vec = CountVectorizer(ngram_range=(1,3), stop_words='english',analyzer='char', max_features=32500)\n",
        "train_char_features = char_vec.fit_transform(X_new)\n",
        "test_char_features = char_vec.fit_transform(df_test[\"clean_tweets\"])\n",
        "\n",
        "train_features = hstack([train_char_features, train_word_features])\n",
        "test_features = hstack([test_char_features, test_word_features])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SDonKChYXWqw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "7e060f43-004e-4ecc-8ed7-d8660812da0f"
      },
      "cell_type": "code",
      "source": [
        "rfc = RandomForestClassifier(bootstrap=True, class_weight='balanced', criterion='gini',\n",
        "            max_depth=100, max_features=1000, max_leaf_nodes=50,\n",
        "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "            min_samples_leaf=3, min_samples_split=10,\n",
        "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
        "            oob_score=False, random_state=None, verbose=0,\n",
        "            warm_start=False)\n",
        "\n",
        "print(rfc)\n",
        "print('=================================================================')\n",
        "\n",
        "# Train Model\n",
        "print('=========================== Training ============================')\n",
        "rfc.fit(train_features, y_train)\n",
        "\n",
        "# Evaluate Model\n",
        "print('========================== Evaluating ===========================')\n",
        "print('Accuracy:\\t{}'.format(round(100*rfc.score(train_features, y_train),4)))\n",
        "\n",
        "# K-Fold Cross Validation\n",
        "print('========================== Validating ===========================')\n",
        "(f1_rfc, acc_rfc) = test_single_model(rfc, X_new, y_train, [word_vec, char_vec], \n",
        "                                      n_splits=3, random_state=1)\n",
        "print('Mean F1 score (3-fold CV):\\t{}%'.format(round(100*f1_rfc,4)))\n",
        "print('Mean Accuracy (3-fold CV):\\t{}%'.format(round(100*acc_rfc,4)))\n",
        "\n",
        "# Predict on test set and write submission\n",
        "#y_pred_proba_rfc = rfc.predict_proba(X_test)\n",
        "#y_pred_rfc = np.argmax(y_pred_proba_rfc,1)\n",
        "#make_submission(y_pred_rfc, {\"UNT\":0, \"TIN\":1}, df_test, \"submissions/taskb_rfc.csv\")"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=100, max_features=1000,\n",
            "            max_leaf_nodes=50, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=3,\n",
            "            min_samples_split=10, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False)\n",
            "=================================================================\n",
            "=========================== Training ============================\n",
            "========================== Evaluating ===========================\n",
            "Accuracy:\t69.0144\n",
            "========================== Validating ===========================\n",
            "Mean F1 score (3-fold CV):\t46.1781%\n",
            "Mean Accuracy (3-fold CV):\t59.9071%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KsQHaDGcbIM9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### CNN"
      ]
    },
    {
      "metadata": {
        "id": "nFr3gm8h1osM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing import sequence\n",
        "from utils.keras_utils import f1_loss\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Embedding, Bidirectional, LSTM, GlobalMaxPool1D, Dropout, Dense\n",
        "from keras.preprocessing import text\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Embedding\n",
        "\n",
        "\n",
        "tokenizer = text.Tokenizer(num_words=15000)\n",
        "tokenizer.fit_on_texts(X_new)\n",
        "\n",
        "X_test = df_test[\"clean_tweets\"]\n",
        "list_tokenized_train = tokenizer.texts_to_sequences(X_new)\n",
        "list_tokenized_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "y_cat = to_categorical(y_train)\n",
        "\n",
        "X_tr = sequence.pad_sequences(list_tokenized_train, maxlen=100)\n",
        "X_te = sequence.pad_sequences(list_tokenized_test, maxlen=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kHoBT1UaYtz1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "outputId": "fb47872b-556c-4dd8-afdf-56690439f2c4"
      },
      "cell_type": "code",
      "source": [
        "# Define Model\n",
        "cnn = Sequential()\n",
        "cnn.add(Embedding(15000, 16, input_length=100))\n",
        "cnn.add(Conv1D(16, 4, activation='relu'))\n",
        "cnn.add(MaxPooling1D(4))\n",
        "cnn.add(Flatten())\n",
        "cnn.add(Dropout(rate=0.25))\n",
        "cnn.add(Dense(units=16, activation='relu'))\n",
        "cnn.add(Dropout(rate=0.15))\n",
        "cnn.add(Dense(units=8, activation='relu'))\n",
        "cnn.add(Dense(units=3, activation='softmax'))\n",
        "cnn.compile(loss=f1_loss, optimizer='adam', metrics=['accuracy'])\n",
        "print(cnn.summary())\n",
        "print('=================================================================')\n",
        "\n",
        "# Train Model\n",
        "print('=========================== Training ============================')\n",
        "cnn.fit(X_tr, y_cat, epochs=20,  batch_size=64, verbose=False)\n",
        "\n",
        "# Evaluate Model\n",
        "print('========================== Evaluating ===========================')\n",
        "evaluation_cnn = cnn.evaluate(X_tr, y_cat, batch_size=64, verbose=1)\n",
        "print('{}:\\t{}'.format(cnn.metrics_names[0], round(100*evaluation_cnn[0],4)))\n",
        "print('{}:\\t{}%'.format(cnn.metrics_names[1], round(100*evaluation_cnn[1],4)))\n",
        "\n",
        "# K-Fold Cross Validation\n",
        "print('========================== Validating ===========================')\n",
        "(f1_cnn, acc_cnn) = test_single_model(cnn, X_new, y_train, tokenizer, epochs=10,\n",
        "                                      n_splits=3, random_state=1, verbose=False)\n",
        "print('Mean F1 score (3-fold CV):\\t{}%'.format(round(100*f1_cnn,4)))\n",
        "print('Mean Accuracy (3-fold CV):\\t{}%'.format(round(100*acc_cnn,4)))\n",
        "\n",
        "# Predict on test set and write submission\n",
        "#y_pred_proba_cnn = cnn.predict(X_te)\n",
        "#y_pred_cnn = np.argmax(y_pred_proba_cnn, axis=1)\n",
        "#make_submission(y_pred_cnn, {\"UNT\":0, \"TIN\":1}, df_test, \"submissions/taskb_cnn.csv\")"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 100, 16)           240000    \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 97, 16)            1040      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 24, 16)            0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 384)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 384)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 16)                6160      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 27        \n",
            "=================================================================\n",
            "Total params: 247,363\n",
            "Trainable params: 247,363\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "=================================================================\n",
            "=========================== Training ============================\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "========================== Evaluating ===========================\n",
            "3876/3876 [==============================] - 0s 52us/step\n",
            "loss:\t16.1218\n",
            "acc:\t88.1837%\n",
            "========================== Validating ===========================\n",
            "Mean F1 score (3-fold CV):\t56.6192%\n",
            "Mean Accuracy (3-fold CV):\t67.6471%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ADtkEyXCbQBH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### LSTM"
      ]
    },
    {
      "metadata": {
        "id": "iyAeuEixZWwA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "efbe1f2e-2a28-4d4a-f1e1-1e020a80decf"
      },
      "cell_type": "code",
      "source": [
        "# Define Model\n",
        "lstm = Sequential()\n",
        "lstm.add(Embedding(15000, 32, input_length=100))\n",
        "lstm.add(Bidirectional(LSTM(16, return_sequences=True)))\n",
        "lstm.add(GlobalMaxPool1D())\n",
        "lstm.add(Dropout(0.3))\n",
        "lstm.add(Dense(8, activation=\"relu\"))\n",
        "lstm.add(Dense(3, activation=\"softmax\"))\n",
        "lstm.compile(loss=f1_loss, optimizer='adam', metrics=['accuracy'])\n",
        "print(lstm.summary())\n",
        "print('=================================================================')\n",
        "\n",
        "# Train Model\n",
        "print('=========================== Training ============================')\n",
        "lstm.fit(X_tr, y_cat, epochs=10,  batch_size=64, verbose=False)\n",
        "\n",
        "# Evaluate Model\n",
        "print('========================== Evaluating ===========================')\n",
        "evaluation_lstm = lstm.evaluate(X_tr, y_cat, batch_size=64, verbose=1)\n",
        "print('{}:\\t{}'.format(lstm.metrics_names[0], round(100*evaluation_lstm[0],4)))\n",
        "print('{}:\\t{}%'.format(lstm.metrics_names[1], round(100*evaluation_lstm[1],4)))\n",
        "\n",
        "# K-Fold Cross Validation\n",
        "print('========================== Validating ===========================')\n",
        "test_single_model(lstm, X_new, y_train, tokenizer, n_splits=3, random_state=1, verbose=False)\n",
        "(f1_lstm, acc_lstm) = test_single_model(lstm, X_new, y_train, tokenizer, \n",
        "                                        n_splits=3, random_state=1, verbose=False)\n",
        "print('Mean F1 score (3-fold CV):\\t{}%'.format(round(100*f1_lstm,4)))\n",
        "print('Mean Accuracy (3-fold CV):\\t{}%'.format(round(100*acc_lstm,4)))\n",
        "\n",
        "# Predict on test set and write submission\n",
        "#y_pred_proba_lstm = lstm.predict(X_te)\n",
        "#y_pred_lstm = np.argmax(y_pred_proba_lstm, axis=1)\n",
        "#make_submission(y_pred_lstm, {\"UNT\":0, \"TIN\":1}, df_test, \"submissions/taskb_lstm.csv\")"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 100, 32)           320000    \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 100, 32)           6272      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_3 (Glob (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 8)                 264       \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 3)                 27        \n",
            "=================================================================\n",
            "Total params: 326,563\n",
            "Trainable params: 326,563\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "=================================================================\n",
            "=========================== Training ============================\n",
            "========================== Evaluating ===========================\n",
            "3876/3876 [==============================] - 4s 998us/step\n",
            "loss:\t31.9633\n",
            "acc:\t82.6883%\n",
            "========================== Validating ===========================\n",
            "Mean F1 score (3-fold CV):\t52.3065%\n",
            "Mean Accuracy (3-fold CV):\t66.2281%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xKv1e6kPbVKR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Bi-LSTM + Conv Layer"
      ]
    },
    {
      "metadata": {
        "id": "D3Rg1IXsax-H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "b041fde3-3674-4736-8139-6c54c7a1c879"
      },
      "cell_type": "code",
      "source": [
        "blc = Sequential()\n",
        "blc.add(Embedding(15000, 16, input_length=100, trainable=True))\n",
        "blc.add(Bidirectional(LSTM(16, return_sequences=True, dropout=0.15, recurrent_dropout=0.15)))\n",
        "blc.add(Conv1D(16, kernel_size=4, padding='valid', kernel_initializer='glorot_uniform'))\n",
        "blc.add(GlobalMaxPool1D())\n",
        "blc.add(Dropout(0.15))\n",
        "blc.add(Dense(8, activation='relu'))\n",
        "blc.add(Dense(3, activation='softmax'))\n",
        "blc.compile(loss=f1_loss, optimizer='adam', metrics=['accuracy'])\n",
        "print(blc.summary())\n",
        "print('=================================================================')\n",
        "\n",
        "# Train Model\n",
        "print('=========================== Training ============================')\n",
        "blc.fit(X_tr, y_cat, epochs=4,  batch_size=64, verbose=False)\n",
        "\n",
        "# Evaluate Model\n",
        "print('========================== Evaluating ===========================')\n",
        "evaluation_blc = blc.evaluate(X_tr, y_cat, batch_size=64, verbose=1)\n",
        "print('{}:\\t{}'.format(blc.metrics_names[0], round(100*evaluation_blc[0],4)))\n",
        "print('{}:\\t{}%'.format(blc.metrics_names[1], round(100*evaluation_blc[1],4)))\n",
        "\n",
        "# K-Fold Cross Validation\n",
        "print('========================== Validating ===========================')\n",
        "test_single_model(blc, X_new, y_train, tokenizer, n_splits=3, random_state=1, verbose=False)\n",
        "(f1_blc, acc_blc) = test_single_model(blc, X_new, y_train, tokenizer, \n",
        "                                      n_splits=3, random_state=1, verbose=False)\n",
        "print('Mean F1 score (3-fold CV):\\t{}%'.format(round(100*f1_blc,4)))\n",
        "print('Mean Accuracy (3-fold CV):\\t{}%'.format(round(100*acc_blc,4)))\n",
        "\n",
        "# Predict on test set and write submission\n",
        "#y_pred_proba_blc = blc.predict(X_te)\n",
        "#y_pred_blc = np.argmax(y_pred_proba_blc, axis=1)\n",
        "#make_submission(y_pred_blc, {\"UNT\":0, \"TIN\":1}, df_test, \"submissions/taskb_blc.csv\")"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 100, 16)           240000    \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 100, 32)           4224      \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 97, 16)            2064      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_2 (Glob (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 3)                 27        \n",
            "=================================================================\n",
            "Total params: 246,451\n",
            "Trainable params: 246,451\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "=================================================================\n",
            "=========================== Training ============================\n",
            "========================== Evaluating ===========================\n",
            "3876/3876 [==============================] - 3s 670us/step\n",
            "loss:\t41.6042\n",
            "acc:\t77.9154%\n",
            "========================== Validating ===========================\n",
            "Mean F1 score (3-fold CV):\t52.114%\n",
            "Mean Accuracy (3-fold CV):\t69.1434%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UZTDlp-YrnGP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}